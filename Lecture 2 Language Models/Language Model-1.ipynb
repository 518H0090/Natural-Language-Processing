{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "9797\n[\"Here are two reasons companies fail: they only do more of the same, or they only do what's new\", 'To me the real, real solution to quality growth is figuring out the balance between two activities: exploration and exploitation', 'Both are necessary, but it can be too much of a good thing', 'Consider Facit', \"I'm actually old enough to remember them\"]\n"
     ]
    }
   ],
   "source": [
    "# đọc file\n",
    "filename='train.txt'\n",
    "lines=[]\n",
    "count=0\n",
    "#Max=-1\n",
    "Max=10000\n",
    "with open(filename,'r') as f:\n",
    "    for s in f:\n",
    "        count+=1\n",
    "        if count>Max and Max!=-1:\n",
    "            break\n",
    "        lines.append(s.strip())\n",
    "print(len(lines))\n",
    "print(lines[:5])          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "all_tokens_count= 182091\n9797\n[['<s>', 'here', 'are', 'two', 'reasons', 'companies', 'fail', ':', 'they', 'only', 'do', 'more', 'of', 'the', 'same', ',', 'or', 'they', 'only', 'do', 'what', \"'s\", 'new', '</s>'], ['<s>', 'to', 'me', 'the', 'real', ',', 'real', 'solution', 'to', 'quality', 'growth', 'is', 'figuring', 'out', 'the', 'balance', 'between', 'two', 'activities', ':', 'exploration', 'and', 'exploitation', '</s>'], ['<s>', 'both', 'are', 'necessary', ',', 'but', 'it', 'can', 'be', 'too', 'much', 'of', 'a', 'good', 'thing', '</s>'], ['<s>', 'consider', 'facit', '</s>'], ['<s>', 'i', \"'m\", 'actually', 'old', 'enough', 'to', 'remember', 'them', '</s>']]\n"
     ]
    }
   ],
   "source": [
    "# tokenize sentences \n",
    "import nltk\n",
    "sentences=[]\n",
    "all_tokens_count=0\n",
    "for line in lines:\n",
    "    tokens = nltk.word_tokenize(line.lower())\n",
    "    all_tokens_count+=len(tokens)\n",
    "    #sentences.append(tokens)\n",
    "    sentences.append(['<s>']+tokens+['</s>'])\n",
    "print('all_tokens_count=',all_tokens_count)\n",
    "print(len(sentences))\n",
    "print(sentences[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "V= 12645\n",
      "n= 182091\n",
      "7960\n",
      "389\n"
     ]
    }
   ],
   "source": [
    "# counting 1-gram \n",
    "from collections import Counter\n",
    "counter_unigram=Counter()\n",
    "for sent in sentences:\n",
    "    counter_unigram.update(sent)\n",
    "V=len(counter_unigram)\n",
    "print('V=',V)\n",
    "n=0\n",
    "for gram in counter_unigram:\n",
    "    n+=counter_unigram[gram]\n",
    "n=n-counter_unigram['<s>']-counter_unigram['</s>']\n",
    "print('n=',n)\n",
    "print(counter_unigram['the'])\n",
    "print(counter_unigram['he'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "191888\n",
      "('<s>', 'here')\n",
      "('here', 'are')\n",
      "('are', 'two')\n",
      "V= 78653\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "from nltk import ngrams\n",
    "bi_grams=[]\n",
    "for sent in sentences:\n",
    "    gram2=ngrams(sent,2)\n",
    "    bi_grams.extend(gram2)\n",
    "print(len(bi_grams))\n",
    "\n",
    "for i in range(3):\n",
    "    print(bi_grams[i])\n",
    "\n",
    "counter_bigram = Counter(bi_grams)\n",
    "print('V=',len(counter_bigram))\n",
    "print(counter_bigram[('here','are')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "182091\n('<s>', 'here', 'are')\n('here', 'are', 'two')\n('are', 'two', 'reasons')\nV= 139716\n2\n"
     ]
    }
   ],
   "source": [
    "tri_grams=[]\n",
    "for sent in sentences:\n",
    "    gram3=ngrams(sent,3)\n",
    "    tri_grams.extend(gram3)\n",
    "print(len(tri_grams))\n",
    "\n",
    "for i in range(3):\n",
    "    print(tri_grams[i])\n",
    "\n",
    "counter_trigram = Counter(tri_grams)\n",
    "print('V=',len(counter_trigram))\n",
    "print(counter_trigram[('here','are','two')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backoff\n",
    "# tính prob theo từng loại: 1-gram, 2-gram, 3-gram\n",
    "def uni_prob(word):\n",
    "    return max(1,counter_unigram[word])/all_tokens_count\n",
    "\n",
    "def bi_prob(word1,word2):\n",
    "    if counter_bigram[(word1,word2)]>0:\n",
    "        return counter_bigram[(word1,word2)]/counter_unigram[word1]\n",
    "    else:\n",
    "        return 0.4*uni_prob(word2)\n",
    "    \n",
    "def tri_prob(word1,word2,word3):\n",
    "    if counter_trigram[(word1,word2,word3)]>0:\n",
    "        return counter_trigram[(word1,word2,word3)]/counter_bigram[(word1,word2)]\n",
    "    else:\n",
    "        return 0.4*bi_prob(word1,word2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tính xác suất của một câu, normalize theo 1 từ \n",
    "def probLM(sent,n):\n",
    "    if n>3 or n<1: # không xét trường hợp này \n",
    "        return 0\n",
    "    tokens=nltk.word_tokenize(sent.lower())\n",
    "    tokens += ['<s>']+tokens\n",
    "    prob=1\n",
    "    for i in range(1,len(tokens)):\n",
    "        if n==1:\n",
    "            prob*=uni_prob(tokens[i])\n",
    "        elif n==2:\n",
    "            prob*=bi_prob(tokens[i-1],tokens[i])\n",
    "        elif n==3:\n",
    "            if i>=2:\n",
    "                prob*=tri_prob(tokens[i-2],tokens[i-1],tokens[i])\n",
    "            else:\n",
    "                prob*=bi_prob(tokens[i-1],tokens[i])\n",
    "    l=len(tokens)-1\n",
    "    return prob**(1/l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "n=1\nprob= 0.001416170749153918\nperplexity= 706.1295402390167\nn=2\nprob= 0.01841810474958468\nperplexity= 54.29440290388997\nn=3\nprob= 0.15967529022070817\nperplexity= 6.26270976941873\n"
     ]
    }
   ],
   "source": [
    "sent='the human body with new abilities is no longer a question'\n",
    "#sent='the human body with new from abilities is no longer a question'\n",
    "#sent='A few years back from'\n",
    "print('n=1')\n",
    "pr=probLM(sent,1)\n",
    "print('prob=',pr)\n",
    "print('perplexity=',1/pr)\n",
    "\n",
    "print('n=2')\n",
    "pr=probLM(sent,2)\n",
    "print('prob=',pr)\n",
    "print('perplexity=',1/pr)\n",
    "\n",
    "print('n=3')\n",
    "pr=probLM(sent,3)\n",
    "print('prob=',pr)\n",
    "print('perplexity=',1/pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "prob= 0.15967529022070817\nperplexity= 6.26270976941873\nprob= 0.0039286601661115295\nperplexity= 254.53970506941815\n"
     ]
    }
   ],
   "source": [
    "# kiểm tra xem 2 xâu có xác suất hơn nhau thế nào, ví dụ cho bài toán speech to text\n",
    "sent1='the human body with new abilities is no longer a question'\n",
    "sent2='the human body with knew abilities is know longer a question'\n",
    "pr=probLM(sent1,3)\n",
    "print('prob=',pr)\n",
    "print('perplexity=',1/pr)\n",
    "\n",
    "pr=probLM(sent2,3)\n",
    "print('prob=',pr)\n",
    "print('perplexity=',1/pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}