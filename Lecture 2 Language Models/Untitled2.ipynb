{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus =\"\"\"\n",
    "Monty Python (sometimes known as The Pythons) were a British surreal comedy group who created the sketch comedy show Monty Python's Flying Circus,\n",
    "that first aired on the BBC on October 5, 1969. Forty-five episodes were made over four series. The Python phenomenon developed from the television series\n",
    "into something larger in scope and impact, spawning touring stage shows, films, numerous albums, several books, and a stage musical.\n",
    "The group's influence on comedy has been compared to The Beatles' influence on music.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<function unigram.<locals>.<lambda> at 0x000001F360B189D0>, {'Monty': 0.020368869071747033, 'Python': 0.030502634779083868, '(': 0.010235103364410202, 'sometimes': 0.010235103364410202, 'known': 0.010235103364410202, 'as': 0.010235103364410202, 'The': 0.040636400486420705, 'Pythons': 0.010235103364410202, ')': 0.010235103364410202, 'were': 0.020368869071747033, 'a': 0.020368869071747033, 'British': 0.010235103364410202, 'surreal': 0.010235103364410202, 'comedy': 0.030502634779083868, 'group': 0.020368869071747033, 'who': 0.010235103364410202, 'created': 0.010235103364410202, 'the': 0.030502634779083868, 'sketch': 0.010235103364410202, 'show': 0.010235103364410202, \"'s\": 0.020368869071747033, 'Flying': 0.010235103364410202, 'Circus': 0.010235103364410202, ',': 0.0710376976084312, 'that': 0.010235103364410202, 'first': 0.010235103364410202, 'aired': 0.010235103364410202, 'on': 0.040636400486420705, 'BBC': 0.010235103364410202, 'October': 0.010235103364410202, '5': 0.010235103364410202, '1969': 0.010235103364410202, '.': 0.040636400486420705, 'Forty-five': 0.010235103364410202, 'episodes': 0.010235103364410202, 'made': 0.010235103364410202, 'over': 0.010235103364410202, 'four': 0.010235103364410202, 'series': 0.020368869071747033, 'phenomenon': 0.010235103364410202, 'developed': 0.010235103364410202, 'from': 0.010235103364410202, 'television': 0.010235103364410202, 'into': 0.010235103364410202, 'something': 0.010235103364410202, 'larger': 0.010235103364410202, 'in': 0.010235103364410202, 'scope': 0.010235103364410202, 'and': 0.020368869071747033, 'impact': 0.010235103364410202, 'spawning': 0.010235103364410202, 'touring': 0.010235103364410202, 'stage': 0.020368869071747033, 'shows': 0.010235103364410202, 'films': 0.010235103364410202, 'numerous': 0.010235103364410202, 'albums': 0.010235103364410202, 'several': 0.010235103364410202, 'books': 0.010235103364410202, 'musical': 0.010235103364410202, 'influence': 0.020368869071747033, 'has': 0.010235103364410202, 'been': 0.010235103364410202, 'compared': 0.010235103364410202, 'to': 0.010235103364410202, 'Beatles': 0.010235103364410202, \"'\": 0.010235103364410202, 'music': 0.010235103364410202, 'abracadabra': 0.01, 'gobbledygook': 0.01, 'rubbish': 0.01})\n"
     ]
    }
   ],
   "source": [
    "import collections, nltk\n",
    "# we first tokenize the text corpus\n",
    "tokens = nltk.word_tokenize(corpus)\n",
    "\n",
    "#here you construct the unigram language model \n",
    "def unigram(tokens):    \n",
    "    model = collections.defaultdict(lambda: 0.01)\n",
    "    for f in tokens:\n",
    "        try:\n",
    "            model[f] += 1\n",
    "        except KeyError:\n",
    "            model [f] = 1\n",
    "            continue\n",
    "    N = float(sum(model.values()))\n",
    "    for word in model:\n",
    "        model[word] = model[word]/N\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computes perplexity of the unigram model on a testset  \n",
    "def perplexity(testset, model):\n",
    "    testset = testset.split()\n",
    "    perplexity = 1\n",
    "    N = 0\n",
    "    for word in testset:\n",
    "        N += 1\n",
    "        perplexity = perplexity * (1/model[word])\n",
    "    perplexity = pow(perplexity, 1/float(N)) \n",
    "    return perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49.09452736318415\n",
      "99.99999999999997\n"
     ]
    }
   ],
   "source": [
    "testset1 = \"Monty\"\n",
    "testset2 = \"abracadabra gobbledygook rubbish\"\n",
    "\n",
    "model = unigram(tokens)\n",
    "print(perplexity(testset1, model))\n",
    "print(perplexity(testset2, model))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
