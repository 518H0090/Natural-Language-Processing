{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "2XFvTyHr3K1y"
   },
   "outputs": [],
   "source": [
    "# thực hiện tiếp các nhiệm vụ sau:\n",
    "# \n",
    "#  lựa chọn đặc trưng 1-gram, 2-gram\n",
    "# convert sang vector với trọng số ở các mode: binary, count, tfidf \n",
    "# chia thành tập Train và Test \n",
    "# xây dựng các mô hình học: NB, SVM, Neural Network \n",
    "# chọn mô hình tốt nhất và viết hàm dự đoán sentiment của một câu đưa vào"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EiICeWDx3K12",
    "outputId": "c14bb3fd-5ef0-4c35-efee-aef2e6befb7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                       comment label\n",
      "0           0                         áo bao đẹp ạ positive   POS\n",
      "1           1                            tuyệt vời positive   POS\n",
      "2           2                     2day ao không giong trong   NEG\n",
      "3           3  mùi thơm bôi lên da mềm da nagative positive   POS\n",
      "4           4                      vải đẹp dày dặn positive   POS\n",
      "(31460, 3)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "filename = 'sentimentVN.csv'\n",
    "df = pd.read_csv(filename)\n",
    "print(df.head(5))\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4xHYowRL3K19",
    "outputId": "0b56d4eb-24f0-407d-8a9a-212a74ece457"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'POS': 20093, 'NEG': 6669, 'NEU': 4698})\n",
      "['áo bao đẹp ạ positive' 'tuyệt vời positive' '2day ao không giong trong'\n",
      " 'mùi thơm bôi lên da mềm da nagative positive' 'vải đẹp dày dặn positive']\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter \n",
    "counter = Counter()\n",
    "labels = df['label']\n",
    "reviews = df.values[:,1] \n",
    "counter.update(labels)\n",
    "print(counter)\n",
    "print(reviews[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WDm5o0si3K2B",
    "outputId": "919b6f44-fd55-4c41-e1cb-875deee812a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19]\n",
      "['áo bao đẹp ạ positive' 'tuyệt vời positive' '2day ao không giong trong'\n",
      " 'mùi thơm bôi lên da mềm da nagative positive' 'vải đẹp dày dặn positive'\n",
      " 'hàng rất đẹp rất chi là ưng ý positive positive'\n",
      " 'chất lượng sản phẩm tốt hạn sử dụng dài positive positive'\n",
      " 'ăn nói và thái độ phục vụ tốt positive'\n",
      " 'đóng gói sản phẩm chắc chắn positive'\n",
      " 'tất sờn hết ca chưa dùng mà vay r' 'cửa hàng phục vụ rất tốt positive'\n",
      " 'mặc thì cũng được positive' 'chất vải khỏi chê'\n",
      " 'thời gian giao hàng rất nhanh'\n",
      " 'chất lượng sản phẩm tuyệt vời positive positive'\n",
      " 'vải hơi thô cứng thời gian giao hàng nhanh nagative'\n",
      " 'chất lượng sản phẩm notpos thật sự  nhe cửa hàng positive'\n",
      " 'rất đáng tiền thời gian giao hàng rất nhanh'\n",
      " 'quần rất đẹp mặc vừa vặn positive'\n",
      " 'cảm giác mua hàng bị hớ thật tệ nagative nagative']\n"
     ]
    }
   ],
   "source": [
    "df = df.values\n",
    "\n",
    "lines = df[:,0]\n",
    "labels = df[:,1]\n",
    "print(lines[:20])\n",
    "print(labels[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "e2jIY-4N3K2D",
    "outputId": "cfee93c0-b598-4eed-d879-3565e74003f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 3 artists>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.bar(counter.keys(),counter.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3rH6PDbf3K2G",
    "outputId": "2ede3cbc-f301-4c14-f934-cdd733c6e646"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\nguyn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\nguyn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "def remove_stop_words(words):\n",
    "    result = [i for i in words if i not in stopwords.words('english')]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2rBV85GX3K2I",
    "outputId": "65feed2e-666c-4c6e-96f4-c5a7374feb13"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-576580512534>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msentences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mremove_stop_words\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-576580512534>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msentences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mremove_stop_words\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[1;34m(text, language, preserve_line)\u001b[0m\n\u001b[0;32m    127\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mpreserve_line\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m     \"\"\"\n\u001b[1;32m--> 129\u001b[1;33m     \u001b[0msentences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    130\u001b[0m     return [\n\u001b[0;32m    131\u001b[0m         \u001b[0mtoken\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msentences\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_treebank_word_tokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[1;34m(text, language)\u001b[0m\n\u001b[0;32m    105\u001b[0m     \"\"\"\n\u001b[0;32m    106\u001b[0m     \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tokenizers/punkt/{0}.pickle\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001b[0m in \u001b[0;36mtokenize\u001b[1;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[0;32m   1270\u001b[0m         \u001b[0mGiven\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msentences\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1271\u001b[0m         \"\"\"\n\u001b[1;32m-> 1272\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentences_from_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1273\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1274\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdebug_decisions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001b[0m in \u001b[0;36msentences_from_text\u001b[1;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[0;32m   1324\u001b[0m         \u001b[0mfollows\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mperiod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1325\u001b[0m         \"\"\"\n\u001b[1;32m-> 1326\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspan_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1328\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_slices_from_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1324\u001b[0m         \u001b[0mfollows\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mperiod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1325\u001b[0m         \"\"\"\n\u001b[1;32m-> 1326\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspan_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1328\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_slices_from_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001b[0m in \u001b[0;36mspan_tokenize\u001b[1;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[0;32m   1314\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m             \u001b[0mslices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_realign_boundaries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1316\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0msl\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mslices\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1317\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001b[0m in \u001b[0;36m_realign_boundaries\u001b[1;34m(self, text, slices)\u001b[0m\n\u001b[0;32m   1355\u001b[0m         \"\"\"\n\u001b[0;32m   1356\u001b[0m         \u001b[0mrealign\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1357\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0msl1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msl2\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_pair_iter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1358\u001b[0m             \u001b[0msl1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msl1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mrealign\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msl1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1359\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msl2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001b[0m in \u001b[0;36m_pair_iter\u001b[1;34m(it)\u001b[0m\n\u001b[0;32m    312\u001b[0m     \u001b[0mit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m         \u001b[0mprev\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    315\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m         \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001b[0m in \u001b[0;36m_slices_from_text\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m   1328\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_slices_from_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m         \u001b[0mlast_break\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1330\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mmatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lang_vars\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mperiod_context_re\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinditer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1331\u001b[0m             \u001b[0mcontext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"after_tok\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1332\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext_contains_sentbreak\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "sentences = [nltk.word_tokenize(line) for line in lines]\n",
    "print(sentences[0])\n",
    "remove_stop_words(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "tnEKDMyl3K2K"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sentences' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-4ae8ff97c4f4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_on_texts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'sentences' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer \n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HTXK9g0B3K2M",
    "outputId": "0a297e9c-6452-4a44-ce5a-08d641c52cf3"
   },
   "outputs": [],
   "source": [
    "X = tokenizer.texts_to_matrix(sentences,mode='binary')\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dWqDKjl53K2N"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h185lmKg3K2Q",
    "outputId": "ca430e94-f7ae-48a3-d29d-ece72ec31657"
   },
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "GaussianNB = GaussianNB()\n",
    "GaussianNB.fit(X_train, y_train)\n",
    "\n",
    "y_pred = GaussianNB.predict(X_test)\n",
    "\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('accuracy is',accuracy_score(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nu8dvzzP3K2R",
    "outputId": "42cff9cd-a6ce-4a93-e19d-1b25308adeb2"
   },
   "outputs": [],
   "source": [
    "#MultinomialNB   \n",
    "from sklearn.naive_bayes import MultinomialNB   \n",
    "model_NB = MultinomialNB()\n",
    "model_NB = model_NB.fit(X_train,y_train)\n",
    "y_pred = model_NB.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('accuracy is',accuracy_score(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "me9W-oSnE6UB",
    "outputId": "f8b4a798-107a-4ded-ece7-f475dfc59335"
   },
   "outputs": [],
   "source": [
    "# Support Vector Machine's \n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "SVC = SGDClassifier()\n",
    "SVC.fit(X_train, y_train)\n",
    "\n",
    "y_pred = SVC.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "# Accuracy score\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('accuracy is',accuracy_score(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QTkGqvgP3K2U",
    "outputId": "712f7244-5734-44e0-e94b-dc44185c9929"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['áo', 'xấu', 'vãi']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Specify a dimension (`num_words` argument), or fit on some text data first.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-a9faca593c5f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_sent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mX_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtexts_to_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras_preprocessing\\text.py\u001b[0m in \u001b[0;36mtexts_to_matrix\u001b[1;34m(self, texts, mode)\u001b[0m\n\u001b[0;32m    379\u001b[0m         \"\"\"\n\u001b[0;32m    380\u001b[0m         \u001b[0msequences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 381\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msequences_to_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    382\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msequences_to_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msequences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras_preprocessing\\text.py\u001b[0m in \u001b[0;36msequences_to_matrix\u001b[1;34m(self, sequences, mode)\u001b[0m\n\u001b[0;32m    400\u001b[0m                 \u001b[0mnum_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 402\u001b[1;33m                 raise ValueError('Specify a dimension (`num_words` argument), '\n\u001b[0m\u001b[0;32m    403\u001b[0m                                  'or fit on some text data first.')\n\u001b[0;32m    404\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Specify a dimension (`num_words` argument), or fit on some text data first."
     ]
    }
   ],
   "source": [
    "input_sent = 'áo xấu vãi' \n",
    "tokens = nltk.word_tokenize(input_sent)\n",
    "print(tokens)\n",
    "X_input = tokenizer.texts_to_matrix([tokens],mode='binary')\n",
    "print(X_input)\n",
    "\n",
    "y_pred = SVC.predict(X_input)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tt3zxAtxVYug",
    "outputId": "db14d6a6-0803-4293-f1cc-b14e40926e62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sản', 'phẩm', 'kém']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Specify a dimension (`num_words` argument), or fit on some text data first.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-ebd418e57512>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_sent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mX_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtexts_to_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras_preprocessing\\text.py\u001b[0m in \u001b[0;36mtexts_to_matrix\u001b[1;34m(self, texts, mode)\u001b[0m\n\u001b[0;32m    379\u001b[0m         \"\"\"\n\u001b[0;32m    380\u001b[0m         \u001b[0msequences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 381\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msequences_to_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    382\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msequences_to_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msequences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras_preprocessing\\text.py\u001b[0m in \u001b[0;36msequences_to_matrix\u001b[1;34m(self, sequences, mode)\u001b[0m\n\u001b[0;32m    400\u001b[0m                 \u001b[0mnum_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 402\u001b[1;33m                 raise ValueError('Specify a dimension (`num_words` argument), '\n\u001b[0m\u001b[0;32m    403\u001b[0m                                  'or fit on some text data first.')\n\u001b[0;32m    404\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Specify a dimension (`num_words` argument), or fit on some text data first."
     ]
    }
   ],
   "source": [
    "input_sent = 'sản phẩm kém' \n",
    "tokens = nltk.word_tokenize(input_sent)\n",
    "print(tokens)\n",
    "X_input = tokenizer.texts_to_matrix([tokens],mode='binary')\n",
    "print(X_input)\n",
    "\n",
    "y_pred = model_NB.predict(X_input)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 723
    },
    "id": "PvqWEYtD3K2W",
    "outputId": "a603521b-050f-4013-8559-2181dbbeaeb5"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-a1b804253f15>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "#Neural network hiện đang lỗi\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5,random_state=42)\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=3, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='sgd',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model.fit(X_train,y_train,batch_size=32, epochs=100,validation_data=(X_val, y_val))\n",
    "model.evaluate(X_test, y_test)[1]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Sentiment_Vietnamese_exercise_.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
