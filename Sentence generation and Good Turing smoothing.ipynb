{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled8.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOXmas3Km7Vt8YlO17enAk4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nthanhkhang/Natural-Language-Processing/blob/main/Sentence%20generation%20and%20Good%20Turing%20smoothing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-TvH3fQVE32"
      },
      "source": [
        "import numpy as np\r\n",
        "from collections import Counter\r\n",
        "import math\r\n",
        "from nltk.translate.bleu_score import sentence_bleu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8SB7pbadb8p"
      },
      "source": [
        "# Bài 1: \r\n",
        "\r\n",
        "### Thêm phương pháp Good Turing smoothing vào mô hình ngôn ngữ 1-gram, 2-gram, 3-gram \r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DMe-RpwKl2h",
        "outputId": "c943abca-50cb-499f-acc1-2e784dae6fd2"
      },
      "source": [
        "!wget \"https://raw.githubusercontent.com/nthanhkhang/Natural-Language-Processing/main/Lecture%202%20Language%20Models/HW2_F17_NLP6320-NLPCorpusTreebank2Parts-CorpusA-Unix.txt\"\r\n",
        "def readData(fileName):\r\n",
        "\tdata = []\r\n",
        "\tfile = open(fileName, \"r\")\r\n",
        "\tfor word in file.read().split():\r\n",
        "\t\tdata.append(word)\r\n",
        "\tfile.close()\r\n",
        "\treturn data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-01-18 13:40:57--  https://raw.githubusercontent.com/nthanhkhang/Natural-Language-Processing/main/Lecture%202%20Language%20Models/HW2_F17_NLP6320-NLPCorpusTreebank2Parts-CorpusA-Unix.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 161867 (158K) [text/plain]\n",
            "Saving to: ‘HW2_F17_NLP6320-NLPCorpusTreebank2Parts-CorpusA-Unix.txt.1’\n",
            "\n",
            "\r          HW2_F17_N   0%[                    ]       0  --.-KB/s               \rHW2_F17_NLP6320-NLP 100%[===================>] 158.07K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2021-01-18 13:40:57 (4.19 MB/s) - ‘HW2_F17_NLP6320-NLPCorpusTreebank2Parts-CorpusA-Unix.txt.1’ saved [161867/161867]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Acqrv-lidjQR"
      },
      "source": [
        "def createBigram(data):\r\n",
        "\tlistOfBigrams = []\r\n",
        "\tbigramCounts = {}\r\n",
        "\tunigramCounts = {}\r\n",
        "\tnbyn = {}\r\n",
        "\tfor i in range(len(data)):\r\n",
        "\t\tif i < len(data) - 1:\r\n",
        "\t\t\tlistOfBigrams.append((data[i], data[i + 1]))\r\n",
        "\t\t\tif (data[i], data[i+1]) in bigramCounts:\r\n",
        "\t\t\t\tbigramCounts[(data[i], data[i + 1])] += 1\r\n",
        "\t\t\telse:\r\n",
        "\t\t\t\tbigramCounts[(data[i], data[i + 1])] = 1\r\n",
        "\t\tif data[i] in unigramCounts:\r\n",
        "\t\t\tunigramCounts[data[i]] += 1\r\n",
        "\t\telse:\r\n",
        "\t\t\tunigramCounts[data[i]] = 1\r\n",
        "\treturn listOfBigrams, unigramCounts, bigramCounts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcdwFenmqYtn"
      },
      "source": [
        "\r\n",
        "# ------------------------------ Simple Bigram Model --------------------------------\r\n",
        "def calcBigramProb(listOfBigrams, unigramCounts, bigramCounts):\r\n",
        "\r\n",
        "\tlistOfProb = {}\r\n",
        "\tfor bigram in listOfBigrams:\r\n",
        "\t\tword1 = bigram[0]\r\n",
        "\t\tword2 = bigram[1]\r\n",
        "\t\tlistOfProb[bigram] = (bigramCounts.get(bigram))/(unigramCounts.get(word1))\r\n",
        "\treturn listOfProb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-tnOGcQqbGS"
      },
      "source": [
        "# ------------------------------- Add One Smoothing ---------------------------------\r\n",
        "def addOneSmothing(listOfBigrams, unigramCounts, bigramCounts):\r\n",
        "\tlistOfProb = {}\r\n",
        "\tcStar = {}\r\n",
        "\tfor bigram in listOfBigrams:\r\n",
        "\t\tword1 = bigram[0]\r\n",
        "\t\tword2 = bigram[1]\r\n",
        "\t\tlistOfProb[bigram] = (bigramCounts.get(bigram) + 1)/(unigramCounts.get(word1) + len(unigramCounts))\r\n",
        "\t\tcStar[bigram] = (bigramCounts[bigram] + 1) * unigramCounts[word1] / (unigramCounts[word1] + len(unigramCounts))\r\n",
        "\treturn listOfProb, cStar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xc5m3JvxqhSn"
      },
      "source": [
        "def goodTuringDiscounting(listOfBigrams, bigramCounts, totalNumberOfBigrams):\r\n",
        "\tlistOfProb = {}\r\n",
        "\tbucket = {}\r\n",
        "\tbucketList = []\r\n",
        "\tcStar = {}\r\n",
        "\tpStar = {}\r\n",
        "\tlistOfCounts = {}\r\n",
        "\ti = 1\r\n",
        "\tfor bigram in bigramCounts.items():\r\n",
        "\t\tkey = bigram[0]\r\n",
        "\t\tvalue = bigram[1]\r\n",
        "\t\t\r\n",
        "\t\tif not value in bucket:\r\n",
        "\t\t\tbucket[value] = 1\r\n",
        "\t\telse:\r\n",
        "\t\t\tbucket[value] += 1\t\r\n",
        "\tbucketList = sorted(bucket.items() , key=lambda t : t[0])\r\n",
        "\tzeroOccurenceProb = bucketList[0][1] / totalNumberOfBigrams\r\n",
        "\tlastItem = bucketList[len(bucketList)-1][0]\r\n",
        "\tfor x in range(1, lastItem):\r\n",
        "\t\tif x not in bucket:\r\n",
        "\t\t\tbucket[x] = 0\r\n",
        "\tbucketList = sorted(bucket.items() , key=lambda t : t[0])\r\n",
        "\tlenBucketList = len(bucketList)\r\n",
        "\tfor k, v in bucketList:\r\n",
        "\t\tif i < lenBucketList-1:\r\n",
        "\t\t\tif v == 0:\r\n",
        "\t\t\t\tcStar[k] = 0\r\n",
        "\t\t\t\tpStar[k] = 0\r\n",
        "\t\t\telse:\r\n",
        "\t\t\t\tcStar[k] = (i+1) * bucketList[i][1] / v\r\n",
        "\t\t\t\tpStar[k] = cStar[k] / totalNumberOfBigrams\r\n",
        "\t\telse:\r\n",
        "\t\t\tcStar[k] = 0\r\n",
        "\t\t\tpStar[k] = 0\r\n",
        "\t\ti += 1\r\n",
        "\tfor bigram in listOfBigrams:\r\n",
        "\t\tlistOfProb[bigram] = pStar.get(bigramCounts[bigram])\r\n",
        "\t\tlistOfCounts[bigram] = cStar.get(bigramCounts[bigram])\r\n",
        "\treturn listOfProb, zeroOccurenceProb, listOfCounts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbwoI_hyqj3C",
        "outputId": "1d56c5e0-0010-4f89-c7f0-3661437803ad"
      },
      "source": [
        "if __name__ == '__main__':\r\n",
        "\tfileName = 'HW2_F17_NLP6320-NLPCorpusTreebank2Parts-CorpusA-Unix.txt'\r\n",
        "\tdata = readData(fileName)\r\n",
        "\tlistOfBigrams, unigramCounts, bigramCounts = createBigram(data)\r\n",
        "\tbigramProb = calcBigramProb(listOfBigrams, unigramCounts, bigramCounts)\r\n",
        "\tbigramAddOne, addOneCstar = addOneSmothing(listOfBigrams, unigramCounts, bigramCounts)\r\n",
        "\tbigramGoodTuring, zeroOccurenceProb, goodTuringCstar = goodTuringDiscounting(listOfBigrams, bigramCounts, len(listOfBigrams))\r\n",
        "\r\n",
        "\t# ------------------------------------- Testing --------------------------------------\r\n",
        "\tinput = \"Richard W. Lock , retired vice president and treasurer of\"\r\n",
        "\tinputList = []\r\n",
        "\toutputProb1 = 1\r\n",
        "\toutputProb2 = 1\r\n",
        "\toutputProb3 = 1\r\n",
        "\tfor i in range(len(input.split())-1):\r\n",
        "\t\tinputList.append((input.split()[i], input.split()[i+1]))\r\n",
        "\tprint (inputList)\r\n",
        "\t# ------------------------------ Simple Bigram Model --------------------------------\r\n",
        "\tfor i in range(len(inputList)):\r\n",
        "\t\tif inputList[i] in bigramProb:\r\n",
        "\t\t\toutputProb1 *= bigramProb[inputList[i]]\r\n",
        "\t\telse:\r\n",
        "\t\t\toutputProb1 *= 0\r\n",
        "\r\n",
        "\tprint ('Bigram Model: ', outputProb1)\r\n",
        "\r\n",
        "\t# ------------------------------- Add One Smoothing ---------------------------------\r\n",
        "\tfor i in range(len(inputList)):\r\n",
        "\t\tif inputList[i] in bigramAddOne:\r\n",
        "\t\t\toutputProb2 *= bigramAddOne[inputList[i]]\r\n",
        "\t\telse:\r\n",
        "\t\t\tif inputList[i][0] not in unigramCounts:\r\n",
        "\t\t\t\tunigramCounts[inputList[i][0]] = 1\r\n",
        "\t\t\tprob = (1) / (unigramCounts[inputList[i][0]] + len(unigramCounts))\r\n",
        "\t\t\taddOneCStar = 1 * unigramCounts[inputList[i][0]] / (unigramCounts[inputList[i][0]] + len(unigramCounts))\r\n",
        "\t\t\toutputProb2 *= prob\r\n",
        "\tprint ('Add One: ', outputProb2)\r\n",
        "\r\n",
        "\t# ---------------------------- Good Turing Discounting ------------------------------\r\n",
        "\tfor i in range(len(inputList)):\r\n",
        "\t\tif inputList[i] in bigramGoodTuring:\r\n",
        "\t\t\toutputProb3 *= bigramGoodTuring[inputList[i]]\r\n",
        "\t\telse:\r\n",
        "\t\t\toutputProb3 *= zeroOccurenceProb\r\n",
        "\tprint ('Good Turing: ' , outputProb3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('Richard', 'W.'), ('W.', 'Lock'), ('Lock', ','), (',', 'retired'), ('retired', 'vice'), ('vice', 'president'), ('president', 'and'), ('and', 'treasurer'), ('treasurer', 'of')]\n",
            "Bigram Model:  1.3484074717156563e-10\n",
            "Add One:  4.602394835477551e-29\n",
            "Good Turing:  1.906026590289504e-40\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHY66AevdKSK"
      },
      "source": [
        "# Bài 2: (optional)\r\n",
        "\r\n",
        "### Viết lại thuật toán tính Bleu score, là thuật toán đo độ tương tự giữa 2 câu:\r\n",
        "\r\n",
        "### https://en.wikipedia.org/wiki/BLEU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zDZTAQmV3b0"
      },
      "source": [
        "def n_gram_generator(sentence,n= 2,n_gram= False):\r\n",
        "    sentence = sentence.lower()\r\n",
        "    sent_arr = np.array(sentence.split())\r\n",
        "    length = len(sent_arr)\r\n",
        "    word_list = []\r\n",
        "    for i in range(length+1):\r\n",
        "        if i < n:\r\n",
        "            continue\r\n",
        "        word_range = list(range(i-n,i))\r\n",
        "        s_list = sent_arr[word_range]\r\n",
        "        string = ' '.join(s_list) \r\n",
        "        word_list.append(string)\r\n",
        "        if n_gram:\r\n",
        "            word_list = list(set(word_list))\r\n",
        "    return word_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCXspHS4Vym7"
      },
      "source": [
        "def bleu_score(original, machine_translated):\r\n",
        "    mt_length = len(machine_translated.split())\r\n",
        "    o_length  = len(original.split())\r\n",
        "    if mt_length > o_length:\r\n",
        "        BP=1\r\n",
        "    else:\r\n",
        "        penality=1-(mt_length/o_length)\r\n",
        "        BP = np.exp(penality)\r\n",
        "    clipped_precision_score = []\r\n",
        "    for ngram_level in range(1, 5):  \r\n",
        "        original_ngram_list = n_gram_generator(original, ngram_level)\r\n",
        "        original_n_gram = Counter(original_ngram_list)      \r\n",
        "        machine_ngram_list = n_gram_generator(machine_translated, ngram_level)\r\n",
        "        machine_n_gram = Counter(machine_ngram_list)\r\n",
        "        num_ngrams_in_translation = sum(machine_n_gram.values()) \r\n",
        "        for j in machine_n_gram:\r\n",
        "            if j in original_n_gram:  \r\n",
        "                if machine_n_gram[j] > original_n_gram[j]: \r\n",
        "                    machine_n_gram[j] = original_n_gram[j]      \r\n",
        "            else:\r\n",
        "                machine_n_gram[j] = 0\r\n",
        "        clipped_precision_score.append(float(sum(machine_n_gram.values())) / num_ngrams_in_translation)\r\n",
        "    weights = [0.25]*4\r\n",
        "\r\n",
        "    s = (w_i * math.log(p_i) for w_i, p_i in zip(weights, clipped_precision_score))\r\n",
        "    s = BP * math.exp(math.fsum(s))\r\n",
        "    return s"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9vfgvhyV15I",
        "outputId": "7f3b5efc-9e38-4fcc-e985-735a7decdfa3"
      },
      "source": [
        "if __name__ == \"__main__\":\r\n",
        "  raw = \"It is a guide to action which ensures that the military alwasy obeys the command of the party\"\r\n",
        "  test = \"It is the guiding principle which guarantees the military forces alwasy being under the command of the party\"\r\n",
        "  print (\"bleu_score:\",bleu_score(raw, test))\r\n",
        "  print (\"sentence_bleu:\",sentence_bleu([raw.split()], test.split()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bleu_score: 0.27098211583470044\n",
            "sentence_bleu: 0.27098211583470044\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}