{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "beam_search.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nthanhkhang/Natural-Language-Processing/blob/main/beam_search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHM1PsLj4OHq"
      },
      "source": [
        "# Thực hành với Beam search\n",
        "\n",
        "Khôi phục dấu câu tiếng Việt sử dụng Beam search & Language model\n",
        "\n",
        "> Click vào ảnh để xem bài hướng dẫn chi tiết\n",
        "\n",
        "[![](https://nguyenvanhieu.vn/wp-content/uploads/2020/07/beam-search.jpg)](https://nguyenvanhieu.vn/thuat-toan-beam-search/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_20ohjigege"
      },
      "source": [
        "import re\n",
        "import json\n",
        "import os\n",
        "import itertools\n",
        "from math import log"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L662vkyPgs67"
      },
      "source": [
        "# Xóa dấu tiếng Việt\n",
        "def remove_vn_accent(s):\n",
        "    s = re.sub('[áàảãạăắằẳẵặâấầẩẫậ]', 'a', s)\n",
        "    s = re.sub('[éèẻẽẹêếềểễệ]', 'e', s)\n",
        "    s = re.sub('[óòỏõọôốồổỗộơớờởỡợ]', 'o', s)\n",
        "    s = re.sub('[íìỉĩị]', 'i', s)\n",
        "    s = re.sub('[úùủũụưứừửữự]', 'u', s)\n",
        "    s = re.sub('[ýỳỷỹỵ]', 'y', s)\n",
        "    s = re.sub('đ', 'd', s)\n",
        "    return s"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1hBPibDgyJt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85141dd8-8415-45de-b63d-9dcc976e8502"
      },
      "source": [
        "# Download VN syllables\n",
        "!wget -O vn_syllables.txt \"https://gist.githubusercontent.com/nguyenvanhieuvn/8d7c3440590a6db732ef6e05498c1566/raw/0164ccb7094b22a48a52844e7fa748cf2820cec9/all-vietnamese-syllables.txt(G%25C3%25B5%2520d%25E1%25BA%25A5u%2520ki%25E1%25BB%2583u%2520c%25C5%25A9)\"\n",
        "# Download language model\n",
        "!wget \"https://github.com/nguyenvanhieuvn/vn-accent-resoration/raw/master/vn_en_nextwords.txt.zip\"\n",
        "!unzip vn_en_nextwords.txt.zip\n",
        "# Download test data\n",
        "!wget \"https://github.com/nguyenvanhieuvn/vn-accent-resoration/raw/master/test.txt\"\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-01-12 07:00:05--  https://gist.githubusercontent.com/nguyenvanhieuvn/8d7c3440590a6db732ef6e05498c1566/raw/0164ccb7094b22a48a52844e7fa748cf2820cec9/all-vietnamese-syllables.txt(G%25C3%25B5%2520d%25E1%25BA%25A5u%2520ki%25E1%25BB%2583u%2520c%25C5%25A9)\n",
            "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 116238 (114K) [text/plain]\n",
            "Saving to: ‘vn_syllables.txt’\n",
            "\n",
            "vn_syllables.txt    100%[===================>] 113.51K  --.-KB/s    in 0.08s   \n",
            "\n",
            "2021-01-12 07:00:06 (1.40 MB/s) - ‘vn_syllables.txt’ saved [116238/116238]\n",
            "\n",
            "--2021-01-12 07:00:06--  https://github.com/nguyenvanhieuvn/vn-accent-resoration/raw/master/vn_en_nextwords.txt.zip\n",
            "Resolving github.com (github.com)... 52.69.186.44\n",
            "Connecting to github.com (github.com)|52.69.186.44|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://github.com/nguyenvanhieuvn/beam-search-tutorial/raw/master/vn_en_nextwords.txt.zip [following]\n",
            "--2021-01-12 07:00:06--  https://github.com/nguyenvanhieuvn/beam-search-tutorial/raw/master/vn_en_nextwords.txt.zip\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/nguyenvanhieuvn/beam-search-tutorial/master/vn_en_nextwords.txt.zip [following]\n",
            "--2021-01-12 07:00:06--  https://raw.githubusercontent.com/nguyenvanhieuvn/beam-search-tutorial/master/vn_en_nextwords.txt.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 32146459 (31M) [application/zip]\n",
            "Saving to: ‘vn_en_nextwords.txt.zip.1’\n",
            "\n",
            "vn_en_nextwords.txt 100%[===================>]  30.66M  55.8MB/s    in 0.5s    \n",
            "\n",
            "2021-01-12 07:00:07 (55.8 MB/s) - ‘vn_en_nextwords.txt.zip.1’ saved [32146459/32146459]\n",
            "\n",
            "Archive:  vn_en_nextwords.txt.zip\n",
            "replace vn_en_nextwords.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJxEZ3P9hQGK"
      },
      "source": [
        "# Tạo bộ từ điển sinh dấu câu cho các từ không dấu\n",
        "map_accents = {}\n",
        "for word in open('vn_syllables.txt').read().splitlines():\n",
        "  word = word.lower()\n",
        "  no_accent_word = remove_vn_accent(word)\n",
        "  if no_accent_word not in map_accents:\n",
        "    map_accents[no_accent_word] = set()\n",
        "  map_accents[no_accent_word].add(word)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbrvxOJLiKO7"
      },
      "source": [
        "print(map_accents['chac'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFDH2rCRqCKi"
      },
      "source": [
        "# Đọc lm\n",
        "lm = {}\n",
        "for line in open('vn_en_nextwords.txt'):\n",
        "  data = json.loads(line)\n",
        "  key = data['s']\n",
        "  lm[key] = data\n",
        "vocab_size = len(lm)\n",
        "total_word = 0\n",
        "for word in lm:\n",
        "  total_word += lm[word]['sum']\n",
        "print(vocab_size, total_word)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S55LZeC_5HMD"
      },
      "source": [
        "lm['khang']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFUYIbcU9LZI"
      },
      "source": [
        "# tính xác suất dùng smoothing\n",
        "def get_proba(current_word, next_word):\n",
        "  if current_word not in lm:\n",
        "    return 1 / total_word;\n",
        "  if next_word not in lm[current_word]['next']:\n",
        "    return 1 / (lm[current_word]['sum'] + vocab_size)\n",
        "  return (lm[current_word]['next'][next_word] + 1) / (lm[current_word]['sum'] + vocab_size)\n",
        "\n",
        "# def get_proba(current_word, next_word):\n",
        "#   try:\n",
        "#     return (lm[current_word]['next'][next_word]) / (lm[current_word]['sum'])\n",
        "#   except:\n",
        "#     return 1e-30"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBQlSHgR34-h"
      },
      "source": [
        "# hàm beam search\n",
        "def beam_search(words, k=3):\n",
        "  sequences = []\n",
        "  for idx, word in enumerate(words):\n",
        "    if idx == 0:\n",
        "      sequences = [([x], 0.0) for x in map_accents.get(word, [word])]\n",
        "    else:\n",
        "      all_sequences = []\n",
        "      for seq in sequences:\n",
        "        for next_word in map_accents.get(word, [word]):\n",
        "          current_word = seq[0][-1]\n",
        "          proba = get_proba(current_word, next_word)\n",
        "          # print(current_word, next_word, proba, log(proba))\n",
        "          proba = log(proba)\n",
        "          new_seq = seq[0].copy()\n",
        "          new_seq.append(next_word)\n",
        "          all_sequences.append((new_seq, seq[1] + proba))\n",
        "      # print(all_sequences) \n",
        "      all_sequences = sorted(all_sequences,key=lambda x: x[1], reverse=True)\n",
        "      sequences = all_sequences[:k]\n",
        "  return sequences\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ko_N1RvRsfbV"
      },
      "source": [
        "# tiền xử lý text\n",
        "def preprocess(sentence):\n",
        "  sentence = sentence.lower()\n",
        "  sentence = re.sub(r'[.,~`!@#$%\\^&*\\(\\)\\[\\]\\\\|:;\\'\"]+', ' ', sentence)\n",
        "  sentence = re.sub(r'\\s+', ' ', sentence).strip()\n",
        "  return sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARdWnejy38xn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17337b0f-33e6-41a2-cf50-455d77c76d8d"
      },
      "source": [
        "# test 1 câu\n",
        "sentence = \"Tuy nhiên giai đoạn từ 2009 đến ngày 17/10/2017 cong ty không còn thực hiện các  trang\"\n",
        "sentence = preprocess(sentence)\n",
        "_sentence = remove_vn_accent(sentence)\n",
        "words = _sentence.split()\n",
        "results = beam_search(words, k=5)\n",
        "print('INP:', sentence)\n",
        "\n",
        "print('OUT:', ' '.join(results[0][0]))\n",
        "print('CMP:', ' '.join(results[0][0]) == sentence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INP: tuy nhiên giai đoạn từ 2009 đến ngày 175/10/2017 công ty không còn thực hiện các trang\n",
            "OUT: tuy nhiên giai đoạn từ 2009 đến ngày 175/10/2017 công ty không còn thực hiện các trang\n",
            "CMP: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQ87WWXQzQOe"
      },
      "source": [
        "# test qua bộ test ~ 5000 câu\n",
        "k = 10\n",
        "sentences = open('test.txt').read().splitlines()\n",
        "test_size = len(sentences)\n",
        "print(test_size)\n",
        "correct = 0\n",
        "for sent in sentences:\n",
        "  try:\n",
        "    sent = preprocess(sent)\n",
        "    _sent = remove_vn_accent(sent)\n",
        "    words = _sent.split()\n",
        "    results = beam_search(words, k)\n",
        "    if ' '.join(results[0][0]) == sent:\n",
        "      correct += 1\n",
        "  except:\n",
        "    print('err', sent)\n",
        "    break\n",
        "\n",
        "print(correct / test_size)\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCpzbFlw2PrL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}